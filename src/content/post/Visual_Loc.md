---
title: "Autolocalizaci√≥n Visual Basada en Marcadores"
description: "En esta pr√°ctica se pretende estimar la posici√≥n y orientaci√≥n de un robot en un entorno 2D mediante la detecci√≥n de marcadores visuales AprilTags, aplicando t√©cnicas de visi√≥n por computadora y transformaciones geom√©tricas."
publishDate: "18 MAY 2025"
tags: [
  "rob√≥tica",
  "visi√≥n por computadora",
  "localizaci√≥n visual",
  "AprilTags",
  "estimaci√≥n de pose"
]
coverImage:
  src: "./images_post/AprilTags/portada.png"
  alt: "Reconstrucci√≥n 3D mediante marcadores visuales"
  width: 1200  # Sin unidades (se asume px)
  height: 600
draft: false
---

## Sistema de Posicionamiento üß≠
El uso de marcadores fiduciales como AprilTags permite obtener una localizaci√≥n precisa y robusta mediante t√©cnicas de visi√≥n artificial. Esta estrategia se basa en la detecci√≥n de marcadores visuales cuya geometr√≠a y posici√≥n en el mundo son conocidas de antemano. A partir de su aparici√≥n en la imagen captada por la c√°mara del robot, es posible estimar la pose relativa del marcador respecto a la c√°mara utilizando algoritmos como solvePnP.

Gracias a esta estimaci√≥n y a la cadena de transformaciones geom√©tricas, es posible inferir directamente la posici√≥n del robot en el entorno global. De esta forma, se logra un sistema de autolocalizaci√≥n visual sin necesidad de construir o cargar un mapa del entorno, , lo que permite una puesta en marcha m√°s directa y flexible en entornos controlados.

La Figura 1, tomada del trabajo de Zhang et al. (2023) sobre localizaci√≥n visual en rob√≥tica agr√≠cola, resume el esquema geom√©trico general para la estimaci√≥n de la pose de un veh√≠culo m√≥vil. Este planteamiento te√≥rico representa el fundamento del reto abordado en esta pr√°ctica.

![Info April Tags](./images_post/AprilTags/info_apriltags_redimensionada.png)
**_Figura 1_**: Descripci√≥n del sistema de coordenadas para la localizaci√≥n del robot.\
_[Zhang, Wei & Gong, Liang & Sun, Yefeng & Gao, Bishu & Yu, Chenrui & Liu, Chengliang. (2023). Precise visual positioning of agricultural mobile robots with a fiducial marker reprojection approach. Measurement Science and Technology. 34. 10.1088/1361-6501/ace8b0. ]_

Por tanto, a priori, la estimaci√≥n de la pose del robot se basa en una cadena de transformaciones que relaciona los distintos sistemas de referencia involucrados.

```math
RT_mundo_robot = RT_mundo_tag¬∑RT_tag_camara¬∑RT_camara_robot
```

## Detecci√≥n de marcadores AprilTags üéØ

El primer desaf√≠o a abordar es la detecci√≥n de los marcadores AprilTags. Para ello, se emplea el detector _pyapriltags_, capaz de identificar en tiempo real las esquinas de cada marcador y extraer su identificador. Gracias a esta informaci√≥n, es posible acceder a la pose absoluta del marcador en el sistema de coordenadas global obteniendo su posici√≥n y orientaci√≥n en el entorno. 

Para facilitar la depuraci√≥n visual y comprobar que la detecci√≥n de marcadores se realiza correctamente, se han a√±adido varios colores a los bordes de los marcadores detectados.

![Colours April Tags](./images_post/AprilTags/tags_colours.png)

Una vez detectado un marcador v√°lido, y conociendo su geometr√≠a real en el mundo, se procede a la obtenci√≥n de la primera transformaci√≥n, la pose del marcador respecto a la c√°mara. Para ello, se necesitan las coordenadas 3D reales de las esquinas del marcador, las coordenadas 2D de esas esquinas obtenidas por el detector y La matriz de par√°metros intr√≠nsecos de la c√°mara. 

Dicha matriz se ha construido a partir de los valores proporcionados por el simulador. 

**Comando: Matriz de intr√≠nsecos.**
```python
    ros2 topic echo /turtlebot3/camera/camera_info
``` 
Con estos par√°metros y asumiendo una lente sin distorsi√≥n, se resuelve el problema PnP mediante _cv2.solvePnP_, obteniendo los vectores de rotaci√≥n y traslaci√≥n que permiten construir la matriz **RT_tag_cam**. 
‚Äã

## V√≠deo üé•
1. [Autolocalizaci√≥n visual basada en marcadores apriltags completa.](https://youtu.be/UpFAeQSnzSg)